pipeline {
    agent any

    environment {
        KUBECTL = '/usr/local/bin/kubectl'
        HELM = '/usr/local/bin/helm'
        AWS_DEFAULT_REGION = 'us-east-1'
    }

    parameters {
        string(name: 'CLUSTER_NAME', defaultValue: 'amazon-prime-cluster', description: 'Enter your EKS cluster name')
    }

    stages {
        
        stage('1. Verify AWS Access') {
            steps {
                script {
                    echo '=== Verifying AWS Credentials ==='
                    sh 'aws sts get-caller-identity'
                    sh 'aws eks list-clusters --region us-east-1'
                }
            }
        }
        
        stage('2. Configure kubectl for EKS') {
            steps {
                script {
                    echo "=== Configuring kubectl for cluster: ${params.CLUSTER_NAME} ==="
                    // NO CREDENTIALS NEEDED - EC2 uses LabInstanceProfile
                    sh "aws eks update-kubeconfig --region us-east-1 --name ${params.CLUSTER_NAME}"
                    
                    // Verify connection
                    sh 'kubectl cluster-info'
                    sh 'kubectl get nodes'
                }
            }
        }

        stage('3. Install/Update Prometheus & Grafana') {
            steps {
                script {
                    echo '=== Configuring Prometheus & Grafana ==='
                    sh """
                    # Add Helm repositories
                    helm repo add stable https://charts.helm.sh/stable || true
                    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
                    helm repo update
                    
                    # Create namespace if it doesn't exist
                    kubectl create namespace prometheus --dry-run=client -o yaml | kubectl apply -f -
                    
                    # Check if release exists and install/upgrade accordingly
                    if helm list -n prometheus | grep -q kube-prometheus-stack; then
                        echo "Upgrading existing Prometheus stack..."
                        helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack -n prometheus
                    else
                        echo "Installing Prometheus stack..."
                        helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack -n prometheus
                    fi
                    
                    # Wait for pods to be ready
                    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n prometheus --timeout=300s || true
                    
                    # Expose services via LoadBalancer
                    echo "Exposing Prometheus and Grafana..."
                    kubectl patch svc kube-prometheus-stack-prometheus -n prometheus -p '{"spec": {"type": "LoadBalancer"}}' || true
                    kubectl patch svc kube-prometheus-stack-grafana -n prometheus -p '{"spec": {"type": "LoadBalancer"}}' || true
                    
                    # Show service endpoints
                    echo "=== Prometheus & Grafana Services ==="
                    kubectl get svc -n prometheus
                    """
                }
            }
        }

        stage('4. Install/Update ArgoCD') {
            steps {
                script {
                    echo '=== Configuring ArgoCD ==='
                    sh """
                    # Create namespace if it doesn't exist
                    kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
                    
                    # Install ArgoCD
                    kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
                    
                    # Wait for ArgoCD pods to be ready
                    echo "Waiting for ArgoCD to be ready..."
                    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s
                    
                    # Expose ArgoCD server via LoadBalancer
                    kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'
                    
                    # Show ArgoCD service endpoint
                    echo "=== ArgoCD Service ==="
                    kubectl get svc argocd-server -n argocd
                    """
                }
            }
        }
        
        stage('5. Display Access Information') {
            steps {
                script {
                    sh """
                    echo "========================================="
                    echo "DEPLOYMENT COMPLETE!"
                    echo "========================================="
                    echo ""
                    echo "=== Prometheus ==="
                    kubectl get svc kube-prometheus-stack-prometheus -n prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' && echo ":9090"
                    echo ""
                    echo "=== Grafana ==="
                    kubectl get svc kube-prometheus-stack-grafana -n prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' && echo ":3000"
                    echo "Grafana default credentials: admin / prom-operator"
                    echo ""
                    echo "=== ArgoCD ==="
                    kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' && echo ""
                    echo "Get ArgoCD password with:"
                    echo "kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d"
                    echo ""
                    echo "=== Cluster Nodes ==="
                    kubectl get nodes
                    echo "========================================="
                    """
                }
            }
        }
		
    }
    
    post {
        success {
            echo 'Deployment pipeline completed successfully!'
        }
        failure {
            echo 'Deployment pipeline failed! Check logs above.'
        }
    }
}